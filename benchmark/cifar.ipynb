{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad75115d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T09:18:25.272138Z",
     "iopub.status.busy": "2025-06-12T09:18:25.271509Z",
     "iopub.status.idle": "2025-06-12T09:18:35.040879Z",
     "shell.execute_reply": "2025-06-12T09:18:35.040141Z"
    },
    "papermill": {
     "duration": 9.774009,
     "end_time": "2025-06-12T09:18:35.042298",
     "exception": false,
     "start_time": "2025-06-12T09:18:25.268289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Building wheel for actix (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\r\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/EmotionEngineer/actix.git -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d262a46c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T09:18:35.048181Z",
     "iopub.status.busy": "2025-06-12T09:18:35.047745Z",
     "iopub.status.idle": "2025-06-12T09:18:49.986844Z",
     "shell.execute_reply": "2025-06-12T09:18:49.986039Z"
    },
    "papermill": {
     "duration": 14.943637,
     "end_time": "2025-06-12T09:18:49.988537",
     "exception": false,
     "start_time": "2025-06-12T09:18:35.044900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 09:18:36.513338: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749719916.708991      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749719916.771881      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Import Necessary Libraries ---\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Layer, Dense, BatchNormalization, Activation, Input, \n",
    "                                     Conv2D, MaxPooling2D, Flatten)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Suppress warnings for a cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='tensorflow')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, module='tensorflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f16f38a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T09:18:49.996778Z",
     "iopub.status.busy": "2025-06-12T09:18:49.996344Z",
     "iopub.status.idle": "2025-06-12T09:18:50.000990Z",
     "shell.execute_reply": "2025-06-12T09:18:50.000302Z"
    },
    "papermill": {
     "duration": 0.010038,
     "end_time": "2025-06-12T09:18:50.002354",
     "exception": false,
     "start_time": "2025-06-12T09:18:49.992316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the List of Activation Functions to Test ---\n",
    "best_of_last_run = [\n",
    "    'ParametricLogish', \n",
    "    'gelu', \n",
    "    'swish', \n",
    "    'OptimA', \n",
    "    'relu', \n",
    "    'WeibullSoftplusActivation', \n",
    "    'A_ELuC', \n",
    "    'mish', \n",
    "    'AdaptiveErfSwish'\n",
    "]\n",
    "\n",
    "# New functions to add to the test\n",
    "new_to_test = [\n",
    "    'A_STReLU', \n",
    "    'ATanSigU', \n",
    "    'SwishLogTanh', \n",
    "    'ArcGaLU', \n",
    "    'ParametricHyperbolicQuadraticActivation', \n",
    "    'RootSoftplus',\n",
    "    'AdaptiveSinusoidalSoftgate', \n",
    "    'ExpTanhGatedActivation', \n",
    "    'HybridSinExpUnit',\n",
    "    'ParametricLogarithmicSwish', \n",
    "    'AdaptiveCubicSigmoid', \n",
    "    'SmoothedAbsoluteGatedUnit',\n",
    "    'GaussianTanhHarmonicUnit', \n",
    "    'SymmetricParametricRationalSigmoid', \n",
    "    'AdaptivePolynomialSwish',\n",
    "    'LogSigmoidGatedElu', \n",
    "    'AdaptiveBipolarExponentialUnit', \n",
    "    'ParametricHyperGaussianGate',\n",
    "    'TanhGatedArcsinhLinearUnit', \n",
    "    'ParametricOddPowerSwish', \n",
    "    'AdaptiveLinearLogTanh'\n",
    "]\n",
    "\n",
    "# Combine the lists for the current experiment\n",
    "activations_to_test = best_of_last_run + new_to_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "515ea4ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T09:18:50.009755Z",
     "iopub.status.busy": "2025-06-12T09:18:50.009540Z",
     "iopub.status.idle": "2025-06-12T09:18:54.032133Z",
     "shell.execute_reply": "2025-06-12T09:18:54.031165Z"
    },
    "papermill": {
     "duration": 4.027752,
     "end_time": "2025-06-12T09:18:54.033374",
     "exception": false,
     "start_time": "2025-06-12T09:18:50.005622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading activation functions from actix...\n",
      "  - WARNING: Activation function 'gelu' not found in the actix library and will be skipped.\n",
      "  - WARNING: Activation function 'swish' not found in the actix library and will be skipped.\n",
      "  - WARNING: Activation function 'relu' not found in the actix library and will be skipped.\n",
      "  - WARNING: Activation function 'mish' not found in the actix library and will be skipped.\n",
      "Loading complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Import and Setup Activations from Actix ---\n",
    "try:\n",
    "    import actix\n",
    "except ImportError:\n",
    "    print(\"Error: 'actix' library is not installed.\")\n",
    "    print(\"Please install it using the command: pip install git+https://github.com/EmotionEngineer/actix.git\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Dynamically create the activation map from the actix library\n",
    "CUSTOM_ACTIVATIONS_MAP = {}\n",
    "print(\"Loading activation functions from actix...\")\n",
    "for name in activations_to_test:\n",
    "    try:\n",
    "        activation_class = getattr(actix, name)\n",
    "        CUSTOM_ACTIVATIONS_MAP[name] = activation_class\n",
    "    except AttributeError:\n",
    "        print(f\"  - WARNING: Activation function '{name}' not found in the actix library and will be skipped.\")\n",
    "print(\"Loading complete.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3131553b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T09:18:54.038726Z",
     "iopub.status.busy": "2025-06-12T09:18:54.038524Z",
     "iopub.status.idle": "2025-06-12T09:18:54.042202Z",
     "shell.execute_reply": "2025-06-12T09:18:54.041482Z"
    },
    "papermill": {
     "duration": 0.007627,
     "end_time": "2025-06-12T09:18:54.043370",
     "exception": false,
     "start_time": "2025-06-12T09:18:54.035743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 3. Constants and Experiment Configuration ---\n",
    "NUM_SEEDS = 3        # Reduced for faster execution, as CIFAR-10 training takes longer\n",
    "EPOCHS = 150\n",
    "PATIENCE = 20        # More aggressive early stopping\n",
    "BATCH_SIZE = 64      # Increased for more stable training on images\n",
    "LEARNING_RATE = 1e-3 # A standard learning rate for Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f787fb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T09:18:54.048280Z",
     "iopub.status.busy": "2025-06-12T09:18:54.048072Z",
     "iopub.status.idle": "2025-06-12T09:18:54.052945Z",
     "shell.execute_reply": "2025-06-12T09:18:54.052287Z"
    },
    "papermill": {
     "duration": 0.008491,
     "end_time": "2025-06-12T09:18:54.054006",
     "exception": false,
     "start_time": "2025-06-12T09:18:54.045515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 4. Layer Naming Utilities ---\n",
    "_layer_name_counters = {}\n",
    "\n",
    "def _get_unique_layer_name(base_name_key):\n",
    "    if base_name_key not in _layer_name_counters:\n",
    "        _layer_name_counters[base_name_key] = 0\n",
    "    _layer_name_counters[base_name_key] += 1\n",
    "    return f\"{base_name_key}_{_layer_name_counters[base_name_key]}\"\n",
    "\n",
    "def _reset_layer_name_counters():\n",
    "    global _layer_name_counters\n",
    "    _layer_name_counters = {}\n",
    "\n",
    "def _add_activation_layer(model, activation_name_str):\n",
    "    unique_name = _get_unique_layer_name(activation_name_str.lower().replace(\" \", \"_\").replace(\"-\",\"_\"))\n",
    "    if activation_name_str in CUSTOM_ACTIVATIONS_MAP:\n",
    "        # Use a custom activation from actix\n",
    "        model.add(CUSTOM_ACTIVATIONS_MAP[activation_name_str](name=unique_name))\n",
    "    else:\n",
    "        # Use a standard TensorFlow activation\n",
    "        model.add(Activation(activation_name_str, name=unique_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5765c79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T09:18:54.058930Z",
     "iopub.status.busy": "2025-06-12T09:18:54.058747Z",
     "iopub.status.idle": "2025-06-12T09:18:54.065698Z",
     "shell.execute_reply": "2025-06-12T09:18:54.065060Z"
    },
    "papermill": {
     "duration": 0.010762,
     "end_time": "2025-06-12T09:18:54.066859",
     "exception": false,
     "start_time": "2025-06-12T09:18:54.056097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 5. Model Definition for Classification Task (CNN) ---\n",
    "def create_cifar10_cnn_model(input_shape, activation_name_str, num_classes=10):\n",
    "    model_name_prefix = activation_name_str.replace(' ','_').replace(\"-\",\"_\").lower()\n",
    "    model = Sequential(name=f\"cifar10_cnn_model_{model_name_prefix}\")\n",
    "\n",
    "    model.add(Input(shape=input_shape, name=_get_unique_layer_name(\"input_layer\")))\n",
    "\n",
    "    # Block 1\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', name=_get_unique_layer_name(\"conv2d\")))\n",
    "    _add_activation_layer(model, activation_name_str)\n",
    "    model.add(BatchNormalization(name=_get_unique_layer_name(\"bn\")))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), name=_get_unique_layer_name(\"maxpool\")))\n",
    "\n",
    "    # Block 2\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', name=_get_unique_layer_name(\"conv2d\")))\n",
    "    _add_activation_layer(model, activation_name_str)\n",
    "    model.add(BatchNormalization(name=_get_unique_layer_name(\"bn\")))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), name=_get_unique_layer_name(\"maxpool\")))\n",
    "    \n",
    "    # Block 3\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', name=_get_unique_layer_name(\"conv2d\")))\n",
    "    _add_activation_layer(model, activation_name_str)\n",
    "    model.add(BatchNormalization(name=_get_unique_layer_name(\"bn\")))\n",
    "\n",
    "    # Classifier Head\n",
    "    model.add(Flatten(name=_get_unique_layer_name(\"flatten\")))\n",
    "    model.add(Dense(128, name=_get_unique_layer_name(\"dense\")))\n",
    "    _add_activation_layer(model, activation_name_str)\n",
    "    model.add(BatchNormalization(name=_get_unique_layer_name(\"bn\")))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax', name=_get_unique_layer_name(\"output_dense\")))\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy', # Loss function for multi-class classification\n",
    "                  metrics=['accuracy'])            # Primary metric is accuracy\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fe066ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T09:18:54.071992Z",
     "iopub.status.busy": "2025-06-12T09:18:54.071423Z",
     "iopub.status.idle": "2025-06-12T09:18:54.075489Z",
     "shell.execute_reply": "2025-06-12T09:18:54.074832Z"
    },
    "papermill": {
     "duration": 0.007574,
     "end_time": "2025-06-12T09:18:54.076515",
     "exception": false,
     "start_time": "2025-06-12T09:18:54.068941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 6. Data Loading and Preprocessing for CIFAR-10 ---\n",
    "def load_and_preprocess_cifar10():\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "    # Normalize images: scale pixel values to the [0, 1] range\n",
    "    x_train = x_train.astype('float32') / 255.0\n",
    "    x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    num_classes = 10\n",
    "    y_train = to_categorical(y_train, num_classes)\n",
    "    y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e840925d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T09:18:54.081733Z",
     "iopub.status.busy": "2025-06-12T09:18:54.081536Z",
     "iopub.status.idle": "2025-06-12T17:34:36.234034Z",
     "shell.execute_reply": "2025-06-12T17:34:36.233257Z"
    },
    "papermill": {
     "duration": 29742.166469,
     "end_time": "2025-06-12T17:34:36.245113",
     "exception": false,
     "start_time": "2025-06-12T09:18:54.078644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.18.0\n",
      "Num GPUs Available: 1, Memory growth enabled.\n",
      "TensorFlow is using GPU.\n",
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "\n",
      "\n",
      "--- Benchmarking on Dataset: CIFAR-10 ---\n",
      "--- Activations to test (30 total): ['ParametricLogish', 'gelu', 'swish', 'OptimA', 'relu', 'WeibullSoftplusActivation', 'A_ELuC', 'mish', 'AdaptiveErfSwish', 'A_STReLU', 'ATanSigU', 'SwishLogTanh', 'ArcGaLU', 'ParametricHyperbolicQuadraticActivation', 'RootSoftplus', 'AdaptiveSinusoidalSoftgate', 'ExpTanhGatedActivation', 'HybridSinExpUnit', 'ParametricLogarithmicSwish', 'AdaptiveCubicSigmoid', 'SmoothedAbsoluteGatedUnit', 'GaussianTanhHarmonicUnit', 'SymmetricParametricRationalSigmoid', 'AdaptivePolynomialSwish', 'LogSigmoidGatedElu', 'AdaptiveBipolarExponentialUnit', 'ParametricHyperGaussianGate', 'TanhGatedArcsinhLinearUnit', 'ParametricOddPowerSwish', 'AdaptiveLinearLogTanh'] ---\n",
      "\n",
      "  --- Testing Activation: ParametricLogish ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1749719940.867173      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Seed 1/3 (Actual seed: 42) for ParametricLogish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1749719949.963132      95 service.cc:148] XLA service 0x7985fc018cb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1749719949.963829      95 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1749719950.498636      95 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1749719953.513899      95 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Seed 1 Loss: 2.0548, Accuracy: 0.7734\n",
      "    Seed 2/3 (Actual seed: 43) for ParametricLogish\n",
      "      Seed 2 Loss: 1.9503, Accuracy: 0.7709\n",
      "    Seed 3/3 (Actual seed: 44) for ParametricLogish\n",
      "      Seed 3 Loss: 2.2176, Accuracy: 0.7800\n",
      "    Results for ParametricLogish: Mean Loss: 2.0742, Mean Accuracy: 0.7748\n",
      "\n",
      "  --- Testing Activation: gelu ---\n",
      "    Seed 1/3 (Actual seed: 42) for gelu\n",
      "      Seed 1 Loss: 2.3705, Accuracy: 0.7718\n",
      "    Seed 2/3 (Actual seed: 43) for gelu\n",
      "      Seed 2 Loss: 1.7991, Accuracy: 0.7526\n",
      "    Seed 3/3 (Actual seed: 44) for gelu\n",
      "      Seed 3 Loss: 1.7475, Accuracy: 0.7576\n",
      "    Results for gelu: Mean Loss: 1.9723, Mean Accuracy: 0.7607\n",
      "\n",
      "  --- Testing Activation: swish ---\n",
      "    Seed 1/3 (Actual seed: 42) for swish\n",
      "      Seed 1 Loss: 2.3374, Accuracy: 0.7736\n",
      "    Seed 2/3 (Actual seed: 43) for swish\n",
      "      Seed 2 Loss: 2.1978, Accuracy: 0.7653\n",
      "    Seed 3/3 (Actual seed: 44) for swish\n",
      "      Seed 3 Loss: 2.2090, Accuracy: 0.7720\n",
      "    Results for swish: Mean Loss: 2.2481, Mean Accuracy: 0.7703\n",
      "\n",
      "  --- Testing Activation: OptimA ---\n",
      "    Seed 1/3 (Actual seed: 42) for OptimA\n",
      "      Seed 1 Loss: 2.0561, Accuracy: 0.7711\n",
      "    Seed 2/3 (Actual seed: 43) for OptimA\n",
      "      Seed 2 Loss: 1.8368, Accuracy: 0.7561\n",
      "    Seed 3/3 (Actual seed: 44) for OptimA\n",
      "      Seed 3 Loss: 2.4920, Accuracy: 0.7788\n",
      "    Results for OptimA: Mean Loss: 2.1283, Mean Accuracy: 0.7687\n",
      "\n",
      "  --- Testing Activation: relu ---\n",
      "    Seed 1/3 (Actual seed: 42) for relu\n",
      "      Seed 1 Loss: 1.7050, Accuracy: 0.7523\n",
      "    Seed 2/3 (Actual seed: 43) for relu\n",
      "      Seed 2 Loss: 1.8513, Accuracy: 0.7543\n",
      "    Seed 3/3 (Actual seed: 44) for relu\n",
      "      Seed 3 Loss: 1.4716, Accuracy: 0.7516\n",
      "    Results for relu: Mean Loss: 1.6760, Mean Accuracy: 0.7527\n",
      "\n",
      "  --- Testing Activation: WeibullSoftplusActivation ---\n",
      "    Seed 1/3 (Actual seed: 42) for WeibullSoftplusActivation\n",
      "      Seed 1 Loss: 1.7256, Accuracy: 0.7490\n",
      "    Seed 2/3 (Actual seed: 43) for WeibullSoftplusActivation\n",
      "      Seed 2 Loss: 2.2250, Accuracy: 0.7631\n",
      "    Seed 3/3 (Actual seed: 44) for WeibullSoftplusActivation\n",
      "      Seed 3 Loss: 2.3297, Accuracy: 0.7753\n",
      "    Results for WeibullSoftplusActivation: Mean Loss: 2.0934, Mean Accuracy: 0.7625\n",
      "\n",
      "  --- Testing Activation: A_ELuC ---\n",
      "    Seed 1/3 (Actual seed: 42) for A_ELuC\n",
      "      Seed 1 Loss: 2.2319, Accuracy: 0.7750\n",
      "    Seed 2/3 (Actual seed: 43) for A_ELuC\n",
      "      Seed 2 Loss: 2.4474, Accuracy: 0.7675\n",
      "    Seed 3/3 (Actual seed: 44) for A_ELuC\n",
      "      Seed 3 Loss: 2.1817, Accuracy: 0.7737\n",
      "    Results for A_ELuC: Mean Loss: 2.2870, Mean Accuracy: 0.7721\n",
      "\n",
      "  --- Testing Activation: mish ---\n",
      "    Seed 1/3 (Actual seed: 42) for mish\n",
      "      Seed 1 Loss: 1.8144, Accuracy: 0.7562\n",
      "    Seed 2/3 (Actual seed: 43) for mish\n",
      "      Seed 2 Loss: 1.7372, Accuracy: 0.7499\n",
      "    Seed 3/3 (Actual seed: 44) for mish\n",
      "      Seed 3 Loss: 2.4519, Accuracy: 0.7699\n",
      "    Results for mish: Mean Loss: 2.0012, Mean Accuracy: 0.7587\n",
      "\n",
      "  --- Testing Activation: AdaptiveErfSwish ---\n",
      "    Seed 1/3 (Actual seed: 42) for AdaptiveErfSwish\n",
      "      Seed 1 Loss: 2.8390, Accuracy: 0.7588\n",
      "    Seed 2/3 (Actual seed: 43) for AdaptiveErfSwish\n",
      "      Seed 2 Loss: 2.0960, Accuracy: 0.7478\n",
      "    Seed 3/3 (Actual seed: 44) for AdaptiveErfSwish\n",
      "      Seed 3 Loss: 2.3402, Accuracy: 0.7629\n",
      "    Results for AdaptiveErfSwish: Mean Loss: 2.4251, Mean Accuracy: 0.7565\n",
      "\n",
      "  --- Testing Activation: A_STReLU ---\n",
      "    Seed 1/3 (Actual seed: 42) for A_STReLU\n",
      "      Seed 1 Loss: 1.7952, Accuracy: 0.7649\n",
      "    Seed 2/3 (Actual seed: 43) for A_STReLU\n",
      "      Seed 2 Loss: 2.0057, Accuracy: 0.7694\n",
      "    Seed 3/3 (Actual seed: 44) for A_STReLU\n",
      "      Seed 3 Loss: 1.6901, Accuracy: 0.7581\n",
      "    Results for A_STReLU: Mean Loss: 1.8303, Mean Accuracy: 0.7641\n",
      "\n",
      "  --- Testing Activation: ATanSigU ---\n",
      "    Seed 1/3 (Actual seed: 42) for ATanSigU\n",
      "      Seed 1 Loss: 2.3292, Accuracy: 0.7759\n",
      "    Seed 2/3 (Actual seed: 43) for ATanSigU\n",
      "      Seed 2 Loss: 2.0865, Accuracy: 0.7750\n",
      "    Seed 3/3 (Actual seed: 44) for ATanSigU\n",
      "      Seed 3 Loss: 2.1493, Accuracy: 0.7781\n",
      "    Results for ATanSigU: Mean Loss: 2.1883, Mean Accuracy: 0.7763\n",
      "\n",
      "  --- Testing Activation: SwishLogTanh ---\n",
      "    Seed 1/3 (Actual seed: 42) for SwishLogTanh\n",
      "      Seed 1 Loss: 2.0417, Accuracy: 0.7777\n",
      "    Seed 2/3 (Actual seed: 43) for SwishLogTanh\n",
      "      Seed 2 Loss: 1.6543, Accuracy: 0.7430\n",
      "    Seed 3/3 (Actual seed: 44) for SwishLogTanh\n",
      "      Seed 3 Loss: 2.1377, Accuracy: 0.7774\n",
      "    Results for SwishLogTanh: Mean Loss: 1.9445, Mean Accuracy: 0.7660\n",
      "\n",
      "  --- Testing Activation: ArcGaLU ---\n",
      "    Seed 1/3 (Actual seed: 42) for ArcGaLU\n",
      "      Seed 1 Loss: 2.3453, Accuracy: 0.7730\n",
      "    Seed 2/3 (Actual seed: 43) for ArcGaLU\n",
      "      Seed 2 Loss: 2.2812, Accuracy: 0.7697\n",
      "    Seed 3/3 (Actual seed: 44) for ArcGaLU\n",
      "      Seed 3 Loss: 1.6756, Accuracy: 0.7509\n",
      "    Results for ArcGaLU: Mean Loss: 2.1007, Mean Accuracy: 0.7645\n",
      "\n",
      "  --- Testing Activation: ParametricHyperbolicQuadraticActivation ---\n",
      "    Seed 1/3 (Actual seed: 42) for ParametricHyperbolicQuadraticActivation\n",
      "      Seed 1 Loss: 1.7465, Accuracy: 0.7463\n",
      "    Seed 2/3 (Actual seed: 43) for ParametricHyperbolicQuadraticActivation\n",
      "      Seed 2 Loss: 2.2250, Accuracy: 0.7701\n",
      "    Seed 3/3 (Actual seed: 44) for ParametricHyperbolicQuadraticActivation\n",
      "      Seed 3 Loss: 1.6293, Accuracy: 0.7422\n",
      "    Results for ParametricHyperbolicQuadraticActivation: Mean Loss: 1.8670, Mean Accuracy: 0.7529\n",
      "\n",
      "  --- Testing Activation: RootSoftplus ---\n",
      "    Seed 1/3 (Actual seed: 42) for RootSoftplus\n",
      "      Seed 1 Loss: 2.5700, Accuracy: 0.7803\n",
      "    Seed 2/3 (Actual seed: 43) for RootSoftplus\n",
      "      Seed 2 Loss: 1.7687, Accuracy: 0.7573\n",
      "    Seed 3/3 (Actual seed: 44) for RootSoftplus\n",
      "      Seed 3 Loss: 1.9866, Accuracy: 0.7637\n",
      "    Results for RootSoftplus: Mean Loss: 2.1084, Mean Accuracy: 0.7671\n",
      "\n",
      "  --- Testing Activation: AdaptiveSinusoidalSoftgate ---\n",
      "    Seed 1/3 (Actual seed: 42) for AdaptiveSinusoidalSoftgate\n",
      "      Seed 1 Loss: 2.1920, Accuracy: 0.7764\n",
      "    Seed 2/3 (Actual seed: 43) for AdaptiveSinusoidalSoftgate\n",
      "      Seed 2 Loss: 2.4874, Accuracy: 0.7742\n",
      "    Seed 3/3 (Actual seed: 44) for AdaptiveSinusoidalSoftgate\n",
      "      Seed 3 Loss: 2.2608, Accuracy: 0.7750\n",
      "    Results for AdaptiveSinusoidalSoftgate: Mean Loss: 2.3134, Mean Accuracy: 0.7752\n",
      "\n",
      "  --- Testing Activation: ExpTanhGatedActivation ---\n",
      "    Seed 1/3 (Actual seed: 42) for ExpTanhGatedActivation\n",
      "      Seed 1 Loss: 1.8292, Accuracy: 0.7440\n",
      "    Seed 2/3 (Actual seed: 43) for ExpTanhGatedActivation\n",
      "      Seed 2 Loss: 1.9141, Accuracy: 0.7378\n",
      "    Seed 3/3 (Actual seed: 44) for ExpTanhGatedActivation\n",
      "      Seed 3 Loss: 2.2906, Accuracy: 0.7647\n",
      "    Results for ExpTanhGatedActivation: Mean Loss: 2.0113, Mean Accuracy: 0.7488\n",
      "\n",
      "  --- Testing Activation: HybridSinExpUnit ---\n",
      "    Seed 1/3 (Actual seed: 42) for HybridSinExpUnit\n",
      "      Seed 1 Loss: 2.4292, Accuracy: 0.6979\n",
      "    Seed 2/3 (Actual seed: 43) for HybridSinExpUnit\n",
      "      Seed 2 Loss: 3.2286, Accuracy: 0.6791\n",
      "    Seed 3/3 (Actual seed: 44) for HybridSinExpUnit\n",
      "      Seed 3 Loss: 2.6510, Accuracy: 0.6269\n",
      "    Results for HybridSinExpUnit: Mean Loss: 2.7696, Mean Accuracy: 0.6680\n",
      "\n",
      "  --- Testing Activation: ParametricLogarithmicSwish ---\n",
      "    Seed 1/3 (Actual seed: 42) for ParametricLogarithmicSwish\n",
      "      Seed 1 Loss: 2.0255, Accuracy: 0.7686\n",
      "    Seed 2/3 (Actual seed: 43) for ParametricLogarithmicSwish\n",
      "      Seed 2 Loss: 1.7218, Accuracy: 0.7468\n",
      "    Seed 3/3 (Actual seed: 44) for ParametricLogarithmicSwish\n",
      "      Seed 3 Loss: 1.8429, Accuracy: 0.7545\n",
      "    Results for ParametricLogarithmicSwish: Mean Loss: 1.8634, Mean Accuracy: 0.7566\n",
      "\n",
      "  --- Testing Activation: AdaptiveCubicSigmoid ---\n",
      "    Seed 1/3 (Actual seed: 42) for AdaptiveCubicSigmoid\n",
      "      Seed 1 Loss: 2.2313, Accuracy: 0.7467\n",
      "    Seed 2/3 (Actual seed: 43) for AdaptiveCubicSigmoid\n",
      "      Seed 2 Loss: 3.6140, Accuracy: 0.7223\n",
      "    Seed 3/3 (Actual seed: 44) for AdaptiveCubicSigmoid\n",
      "      Seed 3 Loss: 1.9884, Accuracy: 0.7189\n",
      "    Results for AdaptiveCubicSigmoid: Mean Loss: 2.6112, Mean Accuracy: 0.7293\n",
      "\n",
      "  --- Testing Activation: SmoothedAbsoluteGatedUnit ---\n",
      "    Seed 1/3 (Actual seed: 42) for SmoothedAbsoluteGatedUnit\n",
      "      Seed 1 Loss: 2.0597, Accuracy: 0.7785\n",
      "    Seed 2/3 (Actual seed: 43) for SmoothedAbsoluteGatedUnit\n",
      "      Seed 2 Loss: 1.7922, Accuracy: 0.7638\n",
      "    Seed 3/3 (Actual seed: 44) for SmoothedAbsoluteGatedUnit\n",
      "      Seed 3 Loss: 2.3116, Accuracy: 0.7807\n",
      "    Results for SmoothedAbsoluteGatedUnit: Mean Loss: 2.0545, Mean Accuracy: 0.7743\n",
      "\n",
      "  --- Testing Activation: GaussianTanhHarmonicUnit ---\n",
      "    Seed 1/3 (Actual seed: 42) for GaussianTanhHarmonicUnit\n",
      "      Seed 1 Loss: 2.2848, Accuracy: 0.7187\n",
      "    Seed 2/3 (Actual seed: 43) for GaussianTanhHarmonicUnit\n",
      "      Seed 2 Loss: 1.6951, Accuracy: 0.7064\n",
      "    Seed 3/3 (Actual seed: 44) for GaussianTanhHarmonicUnit\n",
      "      Seed 3 Loss: 2.0673, Accuracy: 0.7218\n",
      "    Results for GaussianTanhHarmonicUnit: Mean Loss: 2.0157, Mean Accuracy: 0.7156\n",
      "\n",
      "  --- Testing Activation: SymmetricParametricRationalSigmoid ---\n",
      "    Seed 1/3 (Actual seed: 42) for SymmetricParametricRationalSigmoid\n",
      "      Seed 1 Loss: nan, Accuracy: 0.1000\n",
      "    Seed 2/3 (Actual seed: 43) for SymmetricParametricRationalSigmoid\n",
      "      Seed 2 Loss: 0.9919, Accuracy: 0.6435\n",
      "    Seed 3/3 (Actual seed: 44) for SymmetricParametricRationalSigmoid\n",
      "      Seed 3 Loss: nan, Accuracy: 0.1000\n",
      "    Results for SymmetricParametricRationalSigmoid: Mean Loss: 0.9919, Mean Accuracy: 0.2812\n",
      "\n",
      "  --- Testing Activation: AdaptivePolynomialSwish ---\n",
      "    Seed 1/3 (Actual seed: 42) for AdaptivePolynomialSwish\n",
      "      Seed 1 Loss: 2.7013, Accuracy: 0.7564\n",
      "    Seed 2/3 (Actual seed: 43) for AdaptivePolynomialSwish\n",
      "      Seed 2 Loss: 2.7589, Accuracy: 0.7625\n",
      "    Seed 3/3 (Actual seed: 44) for AdaptivePolynomialSwish\n",
      "      Seed 3 Loss: 2.0823, Accuracy: 0.7521\n",
      "    Results for AdaptivePolynomialSwish: Mean Loss: 2.5141, Mean Accuracy: 0.7570\n",
      "\n",
      "  --- Testing Activation: LogSigmoidGatedElu ---\n",
      "    Seed 1/3 (Actual seed: 42) for LogSigmoidGatedElu\n",
      "      Seed 1 Loss: 1.2858, Accuracy: 0.7310\n",
      "    Seed 2/3 (Actual seed: 43) for LogSigmoidGatedElu\n",
      "      Seed 2 Loss: 1.7609, Accuracy: 0.7408\n",
      "    Seed 3/3 (Actual seed: 44) for LogSigmoidGatedElu\n",
      "      Seed 3 Loss: 2.1985, Accuracy: 0.7662\n",
      "    Results for LogSigmoidGatedElu: Mean Loss: 1.7484, Mean Accuracy: 0.7460\n",
      "\n",
      "  --- Testing Activation: AdaptiveBipolarExponentialUnit ---\n",
      "    Seed 1/3 (Actual seed: 42) for AdaptiveBipolarExponentialUnit\n",
      "      Seed 1 Loss: 2.8546, Accuracy: 0.7397\n",
      "    Seed 2/3 (Actual seed: 43) for AdaptiveBipolarExponentialUnit\n",
      "      Seed 2 Loss: 1.1836, Accuracy: 0.6979\n",
      "    Seed 3/3 (Actual seed: 44) for AdaptiveBipolarExponentialUnit\n",
      "      Seed 3 Loss: 1.9849, Accuracy: 0.7158\n",
      "    Results for AdaptiveBipolarExponentialUnit: Mean Loss: 2.0077, Mean Accuracy: 0.7178\n",
      "\n",
      "  --- Testing Activation: ParametricHyperGaussianGate ---\n",
      "    Seed 1/3 (Actual seed: 42) for ParametricHyperGaussianGate\n",
      "      Seed 1 Loss: nan, Accuracy: 0.1000\n",
      "    Seed 2/3 (Actual seed: 43) for ParametricHyperGaussianGate\n",
      "      Seed 2 Loss: 1.4541, Accuracy: 0.4883\n",
      "    Seed 3/3 (Actual seed: 44) for ParametricHyperGaussianGate\n",
      "      Seed 3 Loss: 1.5163, Accuracy: 0.4720\n",
      "    Results for ParametricHyperGaussianGate: Mean Loss: 1.4852, Mean Accuracy: 0.3534\n",
      "\n",
      "  --- Testing Activation: TanhGatedArcsinhLinearUnit ---\n",
      "    Seed 1/3 (Actual seed: 42) for TanhGatedArcsinhLinearUnit\n",
      "      Seed 1 Loss: 1.8724, Accuracy: 0.7577\n",
      "    Seed 2/3 (Actual seed: 43) for TanhGatedArcsinhLinearUnit\n",
      "      Seed 2 Loss: 1.8613, Accuracy: 0.7586\n",
      "    Seed 3/3 (Actual seed: 44) for TanhGatedArcsinhLinearUnit\n",
      "      Seed 3 Loss: 2.0133, Accuracy: 0.7549\n",
      "    Results for TanhGatedArcsinhLinearUnit: Mean Loss: 1.9157, Mean Accuracy: 0.7571\n",
      "\n",
      "  --- Testing Activation: ParametricOddPowerSwish ---\n",
      "    Seed 1/3 (Actual seed: 42) for ParametricOddPowerSwish\n",
      "      Seed 1 Loss: 2.0194, Accuracy: 0.7626\n",
      "    Seed 2/3 (Actual seed: 43) for ParametricOddPowerSwish\n",
      "      Seed 2 Loss: 1.2798, Accuracy: 0.7223\n",
      "    Seed 3/3 (Actual seed: 44) for ParametricOddPowerSwish\n",
      "      Seed 3 Loss: 1.7556, Accuracy: 0.7557\n",
      "    Results for ParametricOddPowerSwish: Mean Loss: 1.6849, Mean Accuracy: 0.7469\n",
      "\n",
      "  --- Testing Activation: AdaptiveLinearLogTanh ---\n",
      "    Seed 1/3 (Actual seed: 42) for AdaptiveLinearLogTanh\n",
      "      Seed 1 Loss: 2.6013, Accuracy: 0.7744\n",
      "    Seed 2/3 (Actual seed: 43) for AdaptiveLinearLogTanh\n",
      "      Seed 2 Loss: 2.1972, Accuracy: 0.7609\n",
      "    Seed 3/3 (Actual seed: 44) for AdaptiveLinearLogTanh\n",
      "      Seed 3 Loss: 2.0869, Accuracy: 0.7498\n",
      "    Results for AdaptiveLinearLogTanh: Mean Loss: 2.2951, Mean Accuracy: 0.7617\n",
      "\n",
      "\n",
      "--- Final Comparison Results ---\n",
      "                                 activation  mean_accuracy  std_accuracy  best_accuracy  mean_loss  std_loss notes\n",
      "10                                 ATanSigU       0.776333      0.001302         0.7781   2.188342  0.102839      \n",
      "15               AdaptiveSinusoidalSoftgate       0.775200      0.000909         0.7764   2.313408  0.126202      \n",
      "0                          ParametricLogish       0.774767      0.003839         0.7800   2.074250  0.109973      \n",
      "20                SmoothedAbsoluteGatedUnit       0.774333      0.007502         0.7807   2.054502  0.212073      \n",
      "6                                    A_ELuC       0.772067      0.003272         0.7750   2.287022  0.115254      \n",
      "2                                     swish       0.770300      0.003595         0.7736   2.248054  0.063316      \n",
      "3                                    OptimA       0.768667      0.009426         0.7788   2.128313  0.272297      \n",
      "14                             RootSoftplus       0.767100      0.009693         0.7803   2.108424  0.338316      \n",
      "11                             SwishLogTanh       0.766033      0.016288         0.7777   1.944540  0.208950      \n",
      "12                                  ArcGaLU       0.764533      0.009734         0.7730   2.100678  0.301729      \n",
      "9                                  A_STReLU       0.764133      0.004645         0.7694   1.830347  0.131231      \n",
      "5                 WeibullSoftplusActivation       0.762467      0.010746         0.7753   2.093431  0.263581      \n",
      "29                    AdaptiveLinearLogTanh       0.761700      0.010059         0.7744   2.295132  0.221112      \n",
      "1                                      gelu       0.760667      0.008133         0.7718   1.972340  0.282295      \n",
      "7                                      mish       0.758667      0.008349         0.7699   2.001191  0.320280      \n",
      "27               TanhGatedArcsinhLinearUnit       0.757067      0.001576         0.7586   1.915668  0.069189      \n",
      "23                  AdaptivePolynomialSwish       0.757000      0.004267         0.7625   2.514141  0.306285      \n",
      "18               ParametricLogarithmicSwish       0.756633      0.009027         0.7686   1.863399  0.124826      \n",
      "8                          AdaptiveErfSwish       0.756500      0.006375         0.7629   2.425075  0.309208      \n",
      "13  ParametricHyperbolicQuadraticActivation       0.752867      0.012300         0.7701   1.866967  0.257671      \n",
      "4                                      relu       0.752733      0.001144         0.7543   1.675980  0.156351      \n",
      "16                   ExpTanhGatedActivation       0.748833      0.011501         0.7647   2.011303  0.200527      \n",
      "28                  ParametricOddPowerSwish       0.746867      0.017598         0.7626   1.684944  0.306054      \n",
      "24                       LogSigmoidGatedElu       0.746000      0.014833         0.7662   1.748405  0.372694      \n",
      "19                     AdaptiveCubicSigmoid       0.729300      0.012382         0.7467   2.611234  0.715949      \n",
      "25           AdaptiveBipolarExponentialUnit       0.717800      0.017123         0.7397   2.007688  0.682346      \n",
      "21                 GaussianTanhHarmonicUnit       0.715633      0.006650         0.7218   2.015719  0.243499      \n",
      "17                         HybridSinExpUnit       0.667967      0.030036         0.6979   2.769613  0.336937      \n",
      "26              ParametricHyperGaussianGate       0.353433      0.179328         0.4883   1.485207  0.031135      \n",
      "22       SymmetricParametricRationalSigmoid       0.281167      0.256208         0.6435   0.991947  0.000000      \n",
      "\n",
      "Results saved to cifar10_activation_comparison_results.csv\n"
     ]
    }
   ],
   "source": [
    "# --- 7. Main Training and Evaluation Loop ---\n",
    "if __name__ == '__main__':\n",
    "    print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(f\"Num GPUs Available: {len(gpus)}, Memory growth enabled.\")\n",
    "            print(\"TensorFlow is using GPU.\")\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "    else:\n",
    "        print(\"TensorFlow is using CPU.\")\n",
    "\n",
    "    dataset_name = \"CIFAR-10\"\n",
    "    (x_train, y_train), (x_test, y_test) = load_and_preprocess_cifar10()\n",
    "    input_shape = x_train.shape[1:]\n",
    "    num_classes = y_train.shape[1]\n",
    "    \n",
    "    all_results_list = []\n",
    "\n",
    "    print(f\"\\n\\n--- Benchmarking on Dataset: {dataset_name} ---\")\n",
    "    print(f\"--- Activations to test ({len(activations_to_test)} total): {activations_to_test} ---\")\n",
    "\n",
    "    for act_name in activations_to_test:\n",
    "        print(f\"\\n  --- Testing Activation: {act_name} ---\")\n",
    "        losses_for_activation = []\n",
    "        accuracies_for_activation = []\n",
    "        \n",
    "        # Pre-check model build\n",
    "        try:\n",
    "            tf.keras.backend.clear_session()\n",
    "            _reset_layer_name_counters()\n",
    "            _ = create_cifar10_cnn_model(input_shape, act_name, num_classes)\n",
    "        except Exception as e:\n",
    "            print(f\"    ERROR: Could not build model with {act_name}. Error: {e}\")\n",
    "            result_entry = {\n",
    "                'activation': act_name,\n",
    "                'mean_loss': np.nan, 'std_loss': np.nan,\n",
    "                'mean_accuracy': np.nan, 'std_accuracy': np.nan, 'best_accuracy': np.nan,\n",
    "                'notes': f'Failed to build model: {e}'\n",
    "            }\n",
    "            all_results_list.append(result_entry)\n",
    "            continue\n",
    "\n",
    "        for i in range(NUM_SEEDS):\n",
    "            seed = 42 + i\n",
    "            print(f\"    Seed {i+1}/{NUM_SEEDS} (Actual seed: {seed}) for {act_name}\")\n",
    "            tf.keras.utils.set_random_seed(seed)\n",
    "            tf.keras.backend.clear_session()\n",
    "            _reset_layer_name_counters()\n",
    "\n",
    "            model = create_cifar10_cnn_model(input_shape, act_name, num_classes)\n",
    "            \n",
    "            callbacks = [\n",
    "                EarlyStopping(monitor='val_accuracy', patience=PATIENCE, restore_best_weights=True, mode='max', verbose=0),\n",
    "            ]\n",
    "            \n",
    "            try:\n",
    "                history = model.fit(x_train, y_train,\n",
    "                                    batch_size=BATCH_SIZE,\n",
    "                                    epochs=EPOCHS,\n",
    "                                    validation_data=(x_test, y_test),\n",
    "                                    callbacks=callbacks,\n",
    "                                    verbose=0) # verbose=0 for a cleaner log\n",
    "                \n",
    "                # evaluate returns [loss, accuracy] as per compiled metrics\n",
    "                eval_results = model.evaluate(x_test, y_test, verbose=0)\n",
    "                loss, accuracy = eval_results[0], eval_results[1]\n",
    "                \n",
    "                losses_for_activation.append(loss)\n",
    "                accuracies_for_activation.append(accuracy)\n",
    "                print(f\"      Seed {i+1} Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"      ERROR during training/evaluation for {act_name} with seed {seed}: {e}\")\n",
    "                losses_for_activation.append(np.nan)\n",
    "                accuracies_for_activation.append(np.nan)\n",
    "\n",
    "        # Calculate final statistics across all seeds\n",
    "        if any(not np.isnan(l) for l in losses_for_activation):\n",
    "            mean_loss = np.nanmean(losses_for_activation)\n",
    "            std_loss = np.nanstd(losses_for_activation)\n",
    "            mean_accuracy = np.nanmean(accuracies_for_activation)\n",
    "            std_accuracy = np.nanstd(accuracies_for_activation)\n",
    "            best_accuracy = np.nanmax(accuracies_for_activation)\n",
    "\n",
    "            result_entry = {\n",
    "                'activation': act_name,\n",
    "                'mean_loss': mean_loss, 'std_loss': std_loss,\n",
    "                'mean_accuracy': mean_accuracy, 'std_accuracy': std_accuracy, 'best_accuracy': best_accuracy,\n",
    "                'notes': ''\n",
    "            }\n",
    "            print(f\"    Results for {act_name}: Mean Loss: {mean_loss:.4f}, Mean Accuracy: {mean_accuracy:.4f}\")\n",
    "        else:\n",
    "            result_entry = {\n",
    "                'activation': act_name,\n",
    "                'mean_loss': np.nan, 'std_loss': np.nan,\n",
    "                'mean_accuracy': np.nan, 'std_accuracy': np.nan, 'best_accuracy': np.nan,\n",
    "                'notes': 'All runs failed'\n",
    "            }\n",
    "        all_results_list.append(result_entry)\n",
    "\n",
    "    # --- 8. Output and Saving Results ---\n",
    "    print(\"\\n\\n--- Final Comparison Results ---\")\n",
    "    results_df = pd.DataFrame(all_results_list)\n",
    "    \n",
    "    # Sort by mean accuracy (from best to worst)\n",
    "    results_df = results_df.sort_values(by=['mean_accuracy'], ascending=False)\n",
    "    \n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 1000)\n",
    "\n",
    "    print(results_df[['activation', 'mean_accuracy', 'std_accuracy', 'best_accuracy', 'mean_loss', 'std_loss', 'notes']])\n",
    "\n",
    "    # Save to CSV\n",
    "    output_filename = \"cifar10_activation_comparison_results.csv\"\n",
    "    results_df.to_csv(output_filename, index=False)\n",
    "    print(f\"\\nResults saved to {output_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29778.720248,
   "end_time": "2025-06-12T17:34:39.999080",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-12T09:18:21.278832",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
